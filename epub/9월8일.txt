Django
	폼데이터 처리

OpenCV(컴퓨터비전)	

이미지 분석







<form name="form1" method="post">
{% csrf_token %}
이름: <input type="text" name="name" id="name"><br>
			  서버전달
국어: <input type="text" name="kor" id="kor"><br>
영어: <input type="text" name="eng" id="eng"><br>
수학: <input type="text" name="mat" id="mat"><br>
<input type="button" value="확인" onclick="check()">
					클릭 함수호출


function check(){
    let kor = $("#kor"); //document.getElementById("kor")
	변수	$ jquery # id
const 상수
    let eng = $("#eng");
    let mat = $("#mat");
    exp = /^[0-9]+$/;
	정규표현식
	/    /   ^ start  $ end  + 반복
    if (!kor.val().match(exp)) { //kor.value
	! not  val() 입력값 
		값.match(정규표현식) 맞으면 true, 틀리면 false
        alert("국어 점수를 입력하세요");
        kor.focus();
        return;
    }
    if (!eng.val().match(exp)) {
        alert("영어 점수를 입력하세요");
        eng.focus();
        return;
    }
    if (!mat.val().match(exp)) {
        alert("수학 점수를 입력하세요");
        mat.focus();
        return;
    }
    document.form1.submit();
}



def point(request):
    try:
        name = request.POST['name']
        kor = request.POST['kor']
        eng = request.POST['eng']
        mat = request.POST['mat']
    except:
        return render(request, 'ch02/point.html')
    total = float(kor) + float(eng) + float(mat)
    average = f'{total / 3:.2f}'
    return render(request, 'ch02/point_result.html',
                  {'name': name, 'kor': kor, 'eng': eng, 'mat': mat, 'total': total, 'average': average})


{% autoescape off %} {{ result }} {% endautoescape %} <br>

{{ result }} <br>

3 x 1 = 3&lt;br&gt;3 x 2 = 6&lt;br&gt;

	&lt; <
	&gt; >
	&lt;br&gt;


handler404 = "mytest.views.error.error404"
handler500 = "mytest.views.error.error500"


	에러 코드
	http status code

	200 정상 처리
	404 잘못된 주소
	500 논리적 오류




http://127.0.0.1:8000/gugu_result/




	web 비연결성

	쿠키 - 클라이언트

		header : url, parameter, cookie
		body : 폼데이터, 첨부파일

	세션 - 서버

def set_cookie(request):
    name = parse.quote('김철수')
		encoding

이름(쿠키): %EA%B9%80%EC%B2%A0%EC%88%98
이름(일반): 김철수 => %EA%B9%80%EC%B2%A0%EC%88%98    인코딩
	  %EA%B9%80%EC%B2%A0%EC%88%98  => 김철수   디코딩

    response = render(request, 'ch03/set_cookie.html', {'name': parse.unquote(name)})
    response.set_cookie('id', 'kim')
			key   value
    response.set_cookie('pwd', '1234')
    response.set_cookie('name', name)
    return response




{% if not request.COOKIES.id %}
		 쿠키배열 key id
  쿠키를 생성해 주세요
  <a href="/set_cookie">쿠키 생성</a>
{% else %}
  {{request.COOKIES.id}}님 환영합니다.<br>
    비번: {{request.COOKIES.pwd}}<br>
    이름(쿠키): {{request.COOKIES.name}}<br>
    이름(일반): {{name}}<br>
{% endif %}


def del_cookie(request):
    response = render(request, 'ch03/del_cookie.html')
    response.delete_cookie('id')
    response.delete_cookie('pwd')
    response.delete_cookie('name')
    return response




def change_cookie(request):
    name = 'Kim Chul'
    response = render(request, 'ch03/change_cookie.html')
    response.set_cookie('id', 'kim')
    response.set_cookie('pwd', '2222')
    response.set_cookie('name', name)
    return response





















def counter(request):
    try:
        last_visit = request.COOKIES['last_visit']
        visits = request.COOKIES['visits']
        t1 = datetime.strptime(str(datetime.now()), '%Y-%m-%d %H:%M:%S.%f')
		날짜 포맷 변경
        t2 = datetime.strptime(last_visit, '%Y-%m-%d %H:%M:%S.%f')
        int_visit = int(visits) + 1
		카운트 증가
        strVisits = str(int_visit)
        strLastVisit = str(datetime.now())
        # 시간제한
        # if (t1 - t2).seconds > 1:
        #     int_visit = int(visits) + 1
        #     strVisits = str(int_visit)
        #     strLastVisit = str(datetime.now())
        # else:
        #     strVisits = visits
        #     strLastVisit = last_visit
    except:
        strVisits = '1'
        strLastVisit = str(datetime.now())

    result = []

	'2 3'
         0 1
    for i in range(0, len(strVisits)):
		  (0,2)
        result.append(f'{strVisits[i]}.gif')
			          2.gif   3.gif

    print(result)
    response = render(request, 'ch03/counter.html', {"result": result})
    response.set_cookie('visits', strVisits)	방문횟수
    response.set_cookie('last_visit', strLastVisit) 최근방문시각
    return response
템플릿 => 내용채우고 => 완성 html
동적 요소 

{% load static %}
	정적 요소

{% for img in result %}
    <img src="/static/images/{{img}}">
{% endfor %}













        if (t1 - t2).seconds > 1:
           현재 - 최근
            int_visit = int(visits) + 1
            strVisits = str(int_visit)
            strLastVisit = str(datetime.now())
        else:
            strVisits = visits
            strLastVisit = last_visit





dst = cv2.blur(img, (5, 5)) #커널 사이즈(값이 클수록 흐려짐)



# Histogram equalization, 히스토그램 평탄화(평활화)
# 히스토그램이 특정 영역에 집중되어 있는 부분을 평탄하게 만들어주는 작업









import numpy as np
#히스토그램 평탄화(평활화)
res1 = cv2.equalizeHist(img1)
ch1 = [0]
ranges1 = [0, 256]
histSize1 = [256]
#히스토그램 계산
# calcHist(images, channels, mask, histSize, ranges(, hist(, accumulate)))
# ranges : 히스토그램 경계값 배열
#   accumulate : True 이면 누적 히스토그램
hist1 = cv2.calcHist([img1], ch1, None, histSize1, ranges1)
hist2 = cv2.calcHist([res1], ch1, None, histSize1, ranges1)
#상수곱, 로그곱, 거듭제곱 변환 기반 명암비 조절 및 히스토그램 계산
multi_lut = np.full(shape=[256], fill_value=0, dtype=np.uint8)
log_lut = np.full(shape=[256], fill_value=0, dtype=np.uint8)
invol1_lut = np.full(shape=[256], fill_value=0, dtype=np.uint8)
multi_v = 2
gamma1 = 0.4
thres1 = 5
thres2 = 100
max_v_log = 255 / np.log(1 + 255)
max_v_invol1 = 255 / np.power(255, gamma1)
for i in range(256):
    val = i * multi_v
    if val > 255 : val = 255
    multi_lut[i] = val
    log_lut[i] = np.round(max_v_log * np.log(1+i))

# 명암비 조절
#LUT(Look Up Table, 룩업 테이블), 결과값을 가진 배열, 반복문을 돌리는 것보다 빠른 연산 속도
res2 = cv2.LUT(img1, multi_lut)
res3 = cv2.LUT(img1, log_lut)
hist3 = cv2.calcHist([res2], ch1, None, histSize1, ranges1)
hist4 = cv2.calcHist([res3], ch1, None, histSize1, ranges1)





# 룩업테이블 설명
a='one' two three
if a=='one':
    print(1)
elif a=='two':
    print(2)
elif a=='three':
    print(3)        

a = dict(zip(['one', 'two', 'three'], [1,2,3]))
print(a['one'])



import numpy as np
histogram, bin = np.histogram(img.ravel(), 256, [0, 256])
				1차원
cumsum = histogram.cumsum() 누계

LUT = np.uint8((cumsum - cumsum.min()) * 255 / (cumsum.max() - cumsum.min()))
equ = LUT[gray]
hist = cv2.equalizeHist(gray) #color 이미지에 적용할 경우 별도의 변환 과정 필요



h=cv.calcHist([gray],[0],None,[256],[0,256])    
plt.plot(h,color='r',linewidth=1)
plt.show()



#마스크 배열
import numpy as np
mask = np.ma.less_equal([-2,-3,-1,0], -1)
                         T   T T  F
mask



import numpy as np
import numpy.ma as ma
# 네번째 항목을 유효하지 않은 것으로 표시
x = np.array([1, 2, 3,--, 5])
             [0, 0, 0, 1, 0]
#마스크 배열:
mx = ma.masked_array(x, mask=[0, 0, 0, 1, 0]) # 네번째 값에 마스크 처리
mx
# 마스킹된 값을 제외한 평균값
#print(mx.mean())






import cv2
import numpy as np
img = cv2.imread("d:/images/autumn.jpg")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#블러링(픽셀의 평균값)
#블러링 마스크의 크기가 크면 영상이 흐려짐
# 1/n
# 3x3 , 모두 더하면 1
blurring_mask1 = np.array([[1 / 9, 1 / 9, 1 / 9],
                           [1 / 9, 1 / 9, 1 / 9],
                           [1 / 9, 1 / 9, 1 / 9]])
# 5x5
blurring_mask2 = np.array([[1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
                           [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
                           [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
                           [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25],
                           [1 / 25, 1 / 25, 1 / 25, 1 / 25, 1 / 25]])
# 스무딩 : 경계선이 뚜렷해짐
smoothing_mask = np.array([[1 / 16, 1 / 8, 1 / 16],
                           [1 / 8, 1 / 4, 1 / 8],
                           [1 / 16, 1 / 8, 1 / 16]])
# 샤프닝(픽셀값의 차이를 크게 하여 날카롭게 하는 기법)
# 중앙값 9, 나머지 픽셀 -1x8, 모두 더하면 1
# 중앙값이 클수록 원본 영상보다 거친 느낌
# 합계가 1이면 평균적인 밝기가 같고, 1보다 크면 밝은 이미지가 되고, 1보다 작으면 어두운 이미지가 됨
sharpening_mask1 = np.array([[-1, -1, -1],
                             [-1, 9, -1],
                             [-1, -1, -1]])
sharpening_mask2 = np.array([[0, -1, 0],
                             [-1, 5, -1],
                             [0, -1, 0]])
blurring_out1 = cv2.filter2D(gray, -1, blurring_mask1)
blurring_out2 = cv2.filter2D(gray, -1, blurring_mask2)
smoothing_out = cv2.filter2D(gray, -1, smoothing_mask)
sharpening_out1 = cv2.filter2D(gray, -1, sharpening_mask1)
sharpening_out2 = cv2.filter2D(gray, -1, sharpening_mask2)



training_images, training_labels = read_images("d:/data/brain_mri/Training")
testing_images , testing_labels  = read_images("d:/data/brain_mri/Testing")



def read_images(folder_path,image_size =(256,256)):
    image_list = []
    label_list = []
    
    for root, subdirs, files in os.walk(folder_path):
        for subdir in subdirs:
            label = subdir
            
            subdir_path = os.path.join(root, subdir)
            for file in os.listdir(subdir_path):
                image_path = os.path.join(subdir_path, file)
                
                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                image = cv2.resize(image, image_size)
                
                image_list.append(image)
                label_list.append(label)
                
    images = np.array(image_list)
    labels = np.array(label_list)
    
    return images, labels






img_base64 = base64.b64encode(img_data).decode("utf-8")
html_code = f'''
<div style="background-color:white; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center;">
    <img src="data:image/png;base64,{img_base64}" style="display: block; margin: 0 auto;">
</div>
'''
display(HTML(html_code))


	<img src="test.jpg">




testing_indices = np.random.permutation(testing_images.shape[0])
testing_images = testing_images[testing_indices] / 255.0
testing_labels = testing_labels[testing_indices]
training_indices = np.random.permutation(training_images.shape[0])
training_images = training_images[training_indices] / 255.0
training_labels = training_labels[training_indices]
print(testing_images.shape, testing_labels.shape)
print(training_images.shape, training_labels.shape)






train_images = np.squeeze(training_images)
			차원축소
train_images = np.expand_dims(train_images, axis=-1)
test_images  = np.squeeze(testing_images)
test_images  = np.expand_dims(test_images, axis=-1)
print(train_images.shape)
print(test_images.shape )

label_encoder        = LabelEncoder()
train_labels_encoded = label_encoder.fit_transform(train_labels)
test_labels_encoded  = label_encoder.transform(test_labels)
num_classes          = len(label_encoder.classes_)
train_labels_onehot  = to_categorical(train_labels_encoded, num_classes=num_classes)
test_labels_onehot   = to_categorical(test_labels_encoded , num_classes=num_classes)


with open("model_plot.png", "rb") as img_file:
			read binary
    img_data = img_file.read()
    
img_base64 = base64.b64encode(img_data).decode("utf-8")
			0~255 => 16진수 00 ~ FF
html_code = f'''
<div style="background-color:white; border-radius:2px; border:#000000 solid; padding: 15px; font-size:100%; text-align:center;">
    <img src="data:image/png;base64,{img_base64}" style="display: block; margin: 0 auto;">
</div>
'''
display(HTML(html_code))




datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.05,
    height_shift_range=0.05,
    zoom_range=0.0,
    horizontal_flip=True
)
datagen.fit(train_images)
train_generator = datagen.flow(train_images, train_labels_onehot, batch_size=32)
test_generator  = datagen.flow(test_images , test_labels_onehot , batch_size=32)


model.fit(train_generator, epochs=3,validation_data=test_generator)






train_dir='d:/data/intel-image-classification/seg_train/seg_train'
test_dir='d:/data/intel-image-classification/seg_test/seg_test'
train_data_gen=ImageDataGenerator(rescale = 1/255.)
test_data_gen=ImageDataGenerator(rescale=1/255.)
train_data = train_data_gen.flow_from_directory(train_dir,
                                          target_size = (224, 224),
                                          batch_size = 32,
                                          class_mode = 'categorical')
val_data = test_data_gen.flow_from_directory(test_dir,
                                        target_size = (224, 224),
                                        batch_size = 32,
                                        class_mode = 'categorical')

images, labels = train_data.next()
			batch size 데이터 공급
len(images), len(labels), images[0].shape



from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras import Sequential, Input
model = Sequential([
            Input(shape = images[0].shape),
            Conv2D(32, (3, 3), padding='same', activation='relu'),
            MaxPooling2D((2, 2), strides=2),
            Conv2D(64, (3, 3), padding='same', activation='relu'),
            MaxPooling2D((2, 2), strides=2),
            Flatten(),
            Dense(128, activation = 'relu'),
            Dense(6, activation = 'softmax'),
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()


from keras.callbacks import ReduceLROnPlateau
reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 3, verbose = 1, 
					기준			3회
factor = 0.5, min_lr = 0.00001)
	곱		최소
classifier=model.fit(train_data,
                         validation_data=val_data,
                         batch_size=64,
                         verbose=1,
                         epochs=2,
                         callbacks=[reduce_lr])



def preprocess_images(path):
    img = image.load_img(path, target_size=(224, 224))
			경로		사이즈
    img_array = image.img_to_array(img)
		이미지=>넘파이배열
    img_array = np.expand_dims(img_array, axis=0)
			차원 증가
    img_preprocessed = img_array / 255.0  
    return img_preprocessed

img_path = "d:/data/intel-image-classification/seg_test/seg_test/mountain/20327.jpg"
img = preprocess_images(img_path)
prediction = loaded_model.predict(img)
predicted_class_index = np.argmax(prediction)
class_labels = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']
predicted_class_label = class_labels[predicted_class_index]
print("Predicted class:", predicted_class_label)




DataPath = "d:/data/Rice_Image_Dataset/"
dic = {'Arborio': 0, 'basmati': 1, 'Ipsala': 2, 'Jasmine': 3, 'Karacadag': 4}
device = "cuda"
fname=[]
limit =500
path=[]
for name in glob.glob(DataPath+"*[!.txt]"):
				* 모든 패턴
				!.txt   확장자가 txt가 아닌
    temp=0
    for filename in os.listdir(name):  
        if temp >= limit:
            break
        fname.append(filename)
        path.append(name)
        temp = temp+1



transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(100),
    transforms.ToTensor(),
])





	obj=RiceData()
		객체
		RiceData[0]
		len(RiceData)


class RiceData(Dataset):
    def __init__(self, filename , root):
        self.filename = filename
        self.root = root
    def __getitem__(self, index):
        path = self.root[index]
        direct = self.filename[index].split(' ')[0]
        filename = self.filename[index]
        label = dic[direct]
        img = cv2.imread(f"{path}/{filename}")
        img = transform(img)
        return img, label
    def __len__(self):
        return len(self.filename)
    
train_ds = RiceData(fname, root=path)
train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
dataiter = iter(train_dl)
		반복처리
data = next(dataiter)
		데이터 읽기
img, labels = data
print(img, labels)




test_split = 0.2  
shuffle_dataset = True
random_seed = 1234
dataset_size = len(train_ds)
indices = list(range(dataset_size))
split = int(np.floor(test_split * dataset_size))
		버림
if shuffle_dataset:
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, test_indices = indices[split:], indices[:split]
# 인덱스를 섞어서 가져오기 위해 SubsetRandomSampler 사용
train_sampler = SubsetRandomSampler(train_indices)
test_sampler = SubsetRandomSampler(test_indices)
train_loader = DataLoader(train_ds, batch_size=1, sampler=train_sampler)
test_loader = DataLoader(train_ds, batch_size=1, sampler=test_sampler)
dataiter = train_loader.__iter__()
data = dataiter.__next__()
img, labels = data




class Counter:
    def __init__(self, stop):
			3
        print('init')
        self.current = 0    
        self.stop = stop    
 
    def __iter__(self):
        print('iter')
        return self         
 
    def __next__(self):
        print('next')
        if self.current < self.stop: 
            r = self.current         
            self.current += 1        
            return r                 
        else:                        
            raise StopIteration      
 'Counter' object is not iterable
for i in Counter(3):
		iterator
    print(i)

init
iter
next
0
next
1
next
2
next

img = img[0].swapaxes(0, 1)
img = img.swapaxes(1, 2)
plt.imshow(img)
plt.show()



# swapaxes 설명
a = np.array([1,2,3,4,5,6]).reshape(2,3) # 2행 3열
print(a)			    3 2
print(np.swapaxes(a, 0, 1)) # 3행 2열



[[1 2 3]
 [4 5 6]]
[[1 4]
 [2 5]
 [3 6]]




class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(32 * 25 * 25, 128)   Flatten() 1차원
        self.fc2 = nn.Linear(128, 5)
        self.relu = nn.ReLU()
    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.pool(x)
        x = self.conv2(x)
        x = self.relu(x)
        x = self.pool(x)
        x = x.view(-1, 32 * 25 * 25)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x





model = CNN()
optimizer = optim.Adam(model.parameters())
for epoch in range(2):
    for i, (images, labels) in enumerate(train_loader):
				제너레이터
        optimizer.zero_grad()
        output = model(images)
      
        loss = nn.functional.cross_entropy(output, labels)
        loss.backward()
        optimizer.step()
        if i % 100 == 0:
            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, i+1, len(train_loader), loss.item()))



data_train = image_dataset_from_directory(train_dir,labels='inferred',
                                       label_mode='binary',interpolation='nearest',image_size=[150,150],batch_size=64,
                                       shuffle=True)
classes_train = data_train.class_names
plt.figure(figsize=(10,10))
for img, label in data_train.skip(50).take(1):
    for i in range(15):
        ax = plt.subplot(3,5,i+1)
        plt.imshow(img[i].numpy().astype('uint8'))
        plt.title(classes_train[int(label[i])])
        plt.axis('off')
clear_output()

classes = next(os.walk(train_dir))[1]
print(classes)





train_datagen = ImageDataGenerator(rescale=1./255,
                                   rotation_range=10,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   zoom_range=0.25,
                                   horizontal_flip=True,
                                   samplewise_center=True,  # 평균 0으로
                                   samplewise_std_normalization=True, # 표준편차 1로
                                   fill_mode='nearest')
test_datagen = ImageDataGenerator(rescale=1./255)





# 1. InceptionV3 모델
IMG_SIZE = (256, 256)                    # Image size is (256, 256) for Inception
train_dataset = train_datagen.flow_from_directory(train_dir, target_size=(IMG_SIZE),
                                         color_mode="rgb",
                                         batch_size=1,
                                         shuffle=True,
                                         class_mode="categorical")
test_dataset = test_datagen.flow_from_directory(test_dir, target_size=(IMG_SIZE),
                                         color_mode="rgb",
                                         batch_size=1,
                                         shuffle=True,
                                         class_mode="categorical")
validation_dataset = train_datagen.flow_from_directory(val_dir, target_size=(IMG_SIZE),
                                         color_mode="rgb",
                                         batch_size=1,
                                         shuffle=True,
                                         class_mode="categorical")


import numpy as np
batch_size=1
n_img = train_dataset.n
	샘플수
steps = n_img // batch_size
	샘플수     배치사이즈
X_train, y_train = [], []
for i in range(steps):
    a, b = train_dataset.next() 제너레이터, 
    X_train.extend(a)
    y_train.extend(b)
    if i > 200:
        break
X_train = np.asarray(X_train)
y_train = np.asarray(y_train)
X_train.shape, y_train.shape


inceptionV3 = InceptionV3(weights='imagenet',include_top=False,input_shape=(256,256,3))
for layer in inceptionV3.layers:  
    layer.trainable = False






model = Sequential()
model.add(inceptionV3)
model.add(Flatten())
model.add(Dense(2,activation='sigmoid'))  
model.compile(optimizer=Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])
model.summary()




callback = EarlyStopping(
    monitor='val_loss',
    min_delta = 0.00001,
    patience=3,
    verbose = 1,
    mode = "auto",
    baseline = None, 
    restore_best_weights = False
    )


import gc
tf.keras.backend.clear_session()
gc.collect() 메모리 정리





(X_train, _), (X_test, _) = mnist.load_data()












	input	hidden	output
	784	36	784
	    encoder   decoder


from keras import layers, models
class AE(models.Model):
    # x_nodes 입력노드수, z_dim 은닉노드수
    # 24x24(픽셀 784개) 입력 이미지들이 원소 36개로 구성된 벡터로 변환된 뒤
    #     24x24 이미지로 복구됨
    def __init__(self, x_nodes=784, z_dim=36):
        x_shape = (x_nodes,)
        #입력 계층
        x = layers.Input(shape=x_shape)
        #은닉 계층
        z = layers.Dense(z_dim, activation='relu')(x)
        #출력 계층
        y = layers.Dense(x_nodes, activation='sigmoid')(z)
        super().__init__(x, y)
        self.x = x
        self.z = z
        self.z_dim = z_dim
        
        self.compile(optimizer='adam',
  loss='binary_crossentropy', metrics=['accuracy'])
    #신경망 외부에서 부호화 결과를 확인하고 싶을 때 호출할 함수
    def Encoder(self):
        return models.Model(self.x, self.z)
    #복호화를 수행하는 함수
    def Decoder(self):
        z_shape = (self.z_dim,)
        z = layers.Input(shape=z_shape)
        # 제일 마지막 레이어가 출력 계층
        y_layer = self.layers[-1]
        y = y_layer(z)
        return models.Model(z, y)




(X_train, _), (X_test, _) = mnist.load_data()
#입력값이 1 이하가 되도록 정규화시킴
X_train = X_train.astype('float32') / 255.
X_test = X_test.astype('float32') / 255.
print(X_train.shape)
	
	28,28 => 784

X_train = X_train.reshape(len(X_train), 784)
X_test = X_test.reshape(len(X_test), 784)
print(X_train.shape)
print(X_test.shape)



x_nodes = 784
z_dim = 36
#모델 생성
autoencoder = AE(x_nodes, z_dim)
		 input	  output
		 784       36
#모델 학습
#입력데이터와 출력데이터를 동일하게 설정
# fit(입력데이터,출력데이터)
history = autoencoder.fit(X_train, X_train,
                          epochs=5,
                          batch_size=256,
                          validation_split=0.2)



def show_ae(autoencoder):
    encoder = autoencoder.Encoder()  784=>36
    decoder = autoencoder.Decoder()  36=>784
    encoder.summary()
    decoder.summary()
    #평가용 이미지들을 넣어서 부호화 결과와 복호화 결과 생성
    encoded_imgs = encoder.predict(X_test) 784=>36
    #부호화된 이미지를 넣어서 복호화 데이터를 생성함
    decoded_imgs = decoder.predict(encoded_imgs) 36=>784
    #화면에 표시할 이미지의 수
    n = 10
    plt.figure(figsize=(20, 6))
    for i in range(n):
        ax = plt.subplot(3, n, i + 1)
        #입력 이미지(평가용 이미지)
        plt.imshow(X_test[i].reshape(28, 28))
        #흑백으로 출력
        plt.gray()
        #이미지 주변 축들이 보이지 않게 함
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        ax = plt.subplot(3, n, i + 1 + n)
        #이미지가 압축된 형태(2차원 이미지를 1차원의 벡터로 압축)
        plt.stem(encoded_imgs[i].reshape(-1))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        ax = plt.subplot(3, n, i + 1 + n + n)
        #복호화한 이미지 출력
        plt.imshow(decoded_imgs[i].reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
    plt.show()




