Django
	방명록 만들기

OpenCV(컴퓨터비전)	

이미지 분석
	생성모델

16:00 ~ 17:00 취업설명회

10/13(금) 3차 프로젝트 발표회(예정), 업체 참관/현장 면접
10/17(화) 수료
10/24(화) 종강





from django.db import models
from datetime import datetime


class Guestbook(models.Model):
    idx = models.AutoField(primary_key=True)
		자동증가 일련번호	
    name = models.CharField(null=False, max_length=50)
    email = models.CharField(null=False, max_length=50)
    passwd = models.CharField(null=False, max_length=50)
    content = models.TextField(null=False)
    post_date = models.DateTimeField(default=datetime.now, blank=True)





from django.urls import include 

urlpatterns = [

    path('guestbook/', include('guestbook.urls')),
]




<form name="form1" method="post">
{% csrf_token %}
<table border="1" width="500px">
  <tr>
    <td>이름</td>
    <td><input name="name" size="40"></td>
  </tr>
  <tr>
    <td>이메일</td>
    <td><input name="email" size="40"></td>
  </tr>
  <tr>
    <td>비밀번호</td>
    <td><input type="password" name="passwd" size="40"></td>
  </tr>
  <tr align="center">
    <td colspan="2"><textarea rows="5" cols="55" name="content"></textarea></td>
  </tr>
  <tr align="center">
    <td colspan="2">
      <input type="button" value="확인" onclick="check()">
    </td>
  </tr>
</table>
</form>


  <script>
    function check(){
      document.form1.action='gb_insert';
	문서	name  	
      document.form1.submit();
    }
  </script>

def insert(request):
    row = Guestbook(name=request.POST['name'],
                    email=request.POST['email'],
                    passwd=request.POST['passwd'],
                    content=request.POST['content'])
    row.save()
    return redirect('/guestbook')


def list(request):
    try:
        searchkey = request.POST['searchkey']
		검색옵션
    except:
        searchkey = 'name'
    try:
        search = request.POST['search']
    except:
        search = ''
    if searchkey == 'name_content':
			이름+내용
        gbList = Guestbook.objects.filter(Q(name__contains=search)
		테이블	모든레코드		조건검색   Q(필드명__contains=키워드)
| Q(content__contains=search)).order_by('-idx')
				정렬	- 내림차순
    elif searchkey == 'name':
        gbList = Guestbook.objects.filter(Q(name__contains=search))\
            .order_by('-idx')
    elif searchkey == 'content':
        gbList = Guestbook.objects.filter(Q(content__contains=search))\
            .order_by('-idx')

    try:
        msg = request.GET['msg']
    except:
        msg = ''
    return render(request, "guestbook/list.html",
                  {"gbList": gbList, "gbCount": len(gbList),
                   "searchkey": searchkey, "search": search, "msg": msg})


<form name="form1" method="post">
{% csrf_token %}
  <select name="searchkey">
		검색옵션
    {% if searchkey == 'name' %}
      <option value="name">이름</option>
      <option value="content">내용</option>
      <option value="name_content">이름+내용</option>
    {% elif searchkey == 'content' %}
      <option value="name">이름</option>
      <option value="content" selected>내용</option>
      <option value="name_content">이름+내용</option>
    {% else %}
    <option value="name">이름</option>
    <option value="content">내용</option>
    <option value="name_content" selected>이름+내용</option>
    {% endif %}
  </select>
  <input name="search" value="{{search}}">
			검색키워드
  <input type="submit" value="조회">
</form>

def passwd_check(request):
    id = request.POST['idx']  글번호
    pwd = request.POST['passwd'] 비번
    row = Guestbook.objects.get(idx=id)
    if row.passwd == pwd:
        return render(request, 'guestbook/edit.html', {'row': row})
    else:
        return redirect('/guestbook/?msg=error')



  {% if msg == 'error' %}
    <script>alert('비밀번호를 확인하세요')</script>
  {% endif %}



def update(request):
    id = request.POST['idx']
    pwd = request.POST['passwd']
    row = Guestbook.objects.get(idx=id)
    if row.passwd == pwd:
        row = Guestbook(idx=id, name=request.POST['name'],
                        email=request.POST['email'], passwd=pwd,
                        content=request.POST['content'])
        row.save()
        return redirect('/guestbook')
    else:
        return redirect('/guestbook/?msg=error')


def delete(request):
    id = request.POST['idx']
    Guestbook.objects.get(idx=id).delete()
    return redirect('/guestbook')







import cv2
img1 = cv2.imread("d:/images/img1.jpg")
img1 = cv2.resize(img1, (320, 240))
		  원본    
img2 = cv2.imread("d:/images/img2.jpg")
img2 = cv2.resize(img2, (320, 240))
img3 = cv2.imread("d:/images/img3.jpg")
img3 = cv2.resize(img3, (320, 240))
img4 = cv2.imread("d:/images/img4.jpg")
img4 = cv2.resize(img4, (320, 240))
img5 = cv2.imread("d:/images/img5.jpg")
img5 = cv2.resize(img5, (320, 240))


import matplotlib.pyplot as plt
plt.figure(figsize=(20,6))
for idx,img in enumerate([img1,img2,img3,img4,img5]):
    plt.subplot(1,5,idx+1)    
    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(image)
    plt.axis("off")
plt.show()






import numpy as np
# 마스크 선언 및 초기화
mask = np.full(shape=img5.shape, fill_value=0, dtype=np.uint8)
h, w, _ = img5.shape
H  W  C
x = (int)(w/2) - 60
y = (int)(h/2) - 60
cv2.rectangle(mask, (x,y), (x+120, y+120), (255,255,255), -1)
# 산술 및 논리 연산 수행
ress = []
ress.append(cv2.add(img1, img2))
		    1     3     4
		    5    10    15
		    255  10    255
# 이미지에 가중치를 곱하는 방식
ress.append(cv2.addWeighted(img1, 0.7, img2, 0.3, 0))
ress.append(cv2.subtract(img3, img4))
# 뺄셈 연산을 수행한 후 절대값을 저장하는 방식
ress.append(cv2.absdiff(img3, img4))
ress.append(cv2.bitwise_not(img5))
			111111111111 255
			000000000000 0	
		
ress.append(cv2.bitwise_and(img5, mask))






import cv2
import numpy as np
import matplotlib.pyplot as plt
img = cv2.imread("d:/images/rear_garden.PNG")
print(img.shape)
(496, 819, 3)
 H    W   C

(height, width) = img.shape[:2] # height,width
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.imshow(img)




#이미지의 중심 좌표 구하기
(height, width) = img.shape[:2]
center = (width // 2, height // 2)
		정수몫
plt.imshow(img)
print("중심좌표:",center)




# 이미지 회전
# 중심좌표, 각도(+:반시계방향, -:시계방향), 스케일
rotate = cv2.getRotationMatrix2D(center, -90, 1.5)  
rotated = cv2.warpAffine(img, rotate, (width, height))
plt.imshow(rotated)


# 이미지 resize
ratio = 400.0 / width
dimension = (400, int(height * ratio))
resized = cv2.resize(img, dimension, interpolation = cv2.INTER_AREA)
print(dimension)
plt.imshow(resized)
# x축의 범위 확인





import cv2
import matplotlib.pyplot as plt
plt.figure(figsize=(12,8))
img = cv2.imread("d:/images/plane.jpg")
image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.subplot(2,2,1)
plt.imshow(image_rgb)
plt.axis("off")
options=[1,0,-1] #좌우, 상하, 상하좌우
for idx,option in enumerate(options):
    dst = cv2.flip(img, option)
			 1 좌우
			 0 상하
			 -1 상하+좌우
    image_rgb = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)
    plt.subplot(2,2,idx+2)
    plt.imshow(image_rgb)
    plt.axis("off")
plt.show()

import numpy as np
# 배경을 제거하고자 하는 전경 주위에 사각형 박스를 그리고 grabCut 알고리즘 적용
# 사각영역: x, y, width, height
rect = (0, 56, 256, 150)
# 초기 마스크 생성
mask1 = np.zeros(image_rgb.shape[:2], np.uint8)
# grabCut에 사용할 임시 배열 생성
bgdModel = np.zeros((1, 65), np.float64)

fgdModel = np.zeros((1, 65), np.float64)
# grabCut 실행
cv2.grabCut(image_rgb, # 원본 이미지
           mask1,       # 마스크
           rect,  # 사각영역
           bgdModel,   # 배경을 위한 임시 배열
           fgdModel,   # 전경을 위한 임시 배열
           5,          # 반복 횟수
           cv2.GC_INIT_WITH_RECT) # 사각 영역으로 초기화
# 배경인 곳은 0, 그 외에는 1로 설정한 마스크 생성
mask2 = np.where((mask1==2) | (mask1==0), 0, 1).astype('uint8')
image_rgb_nobg = image_rgb * mask2[:, :, np.newaxis]

ROI	Region Of Interest












import cv2
# blur 처리에 사용할 커널 크기
ksize = 30              
win_title = 'mosaic'    
img = cv2.imread('d:/images/apple.jpg')
while True:
    x,y,w,h = cv2.selectROI(win_title, img, False) # 관심영역 선택
    if w > 0 and h > 0:
        roi = img[y:y+h, x:x+w]   # 관심영역 지정
        roi = cv2.blur(roi, (ksize, ksize)) # blur(모자이크) 처리
        img[y:y+h, x:x+w] = roi   # 원본 이미지에 적용
        cv2.imshow(win_title, img)
    else:
        break
    
cv2.destroyAllWindows()







from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import RMSprop
import numpy as np
# fake data 생성
def makeZ(m, n):
    z = np.random.uniform(-1.0, 1.0, size=[m, n])
    return z

def myOptimizer(lr):
    return RMSprop(learning_rate=lr)
    
# 판별 모델
def build_D():
    d_x = Input(batch_shape=(None, d_input))
    d_h = Dense(d_hidden, activation='relu')(d_x)
    d_o = Dense(d_output, activation='sigmoid')(d_h)
			0/1 이진분류
    
    d_model = Model(d_x, d_o)
    d_model.compile(loss='binary_crossentropy', optimizer=myOptimizer(0.01))
    
    return d_model


# 생성 모델
def build_G():
    g_x = Input(batch_shape=(None, g_input))    
    g_h = Dense(g_hidden, activation='relu')(g_x)
    g_o = Dense(g_output, activation='linear')(g_h)
    
    g_model = Model(g_x, g_o)
    
    return g_model
    
# GAN 모델
def build_GAN(discriminator, generator):
    discriminator.trainable = False
    z = Input(batch_shape=(None, g_input))
    Gz = generator(z)
	가짜
    DGz = discriminator(Gz)
	판별
    
    gan_model = Model(z, DGz)
    gan_model.compile(loss='binary_crossentropy', optimizer=myOptimizer(0.01))
    
    return gan_model

n_batch_cnt = 5
n_batch_size = int( real_data.shape[0] / n_batch_cnt)
EPOCHS = 100
for epoch in range(EPOCHS):
    X = real_data[:]
		실제
    Z = makeZ(m=X.shape[0], n=g_input)
		가짜
    Gz = G.predict(Z) # 가짜 데이터로부터 분포 생성
    
    # discriminator 학습 데이터 준비
    d_target = np.zeros(X.shape[0]*2)
    d_target[:X.shape[0]] = 1
	진짜데이터 1
    d_target[X.shape[0]:] = 0        
	가짜데이터 0
    bX_Gz = np.concatenate([X, Gz])
    
    # generator 학습 데이터 준비
    g_target = np.zeros(Z.shape[0])
    g_target[:] = 1
    
    # discriminator 학습        
    loss_D = D.train_on_batch(bX_Gz, d_target) # loss 계산
    
    # generator 학습        
    loss_G = GAN.train_on_batch(Z, g_target)
        
    if epoch % 10 == 0:
        print("Epoch: %d, D-loss = %.4f, G-loss = %.4f" %(epoch, loss_D, loss_G))




import matplotlib.pyplot as plt
import os    
os.environ['KMP_DUPLICATE_LIB_OK']='True'
#오염된 이미지
plt.imshow(broken_image.view(100,100))
plt.axis('off')
plt.show()



#이미지에 노이즈를 추가하는 함수
def weird_function(x, n_iter=5):
    h = x    
    filt = torch.tensor([-1./3, 1./3, -1./3])
    for i in range(n_iter):
        zero_tensor = torch.tensor([1.0*0])
        h_l = torch.cat( (zero_tensor, h[:-1]), 0) #텐서 연결
        h_r = torch.cat((h[1:], zero_tensor), 0 )
        h = filt[0] * h + filt[2] * h_l + filt[1] * h_r
        if i % 2 == 0:
            h = torch.cat( (h[h.shape[0]//2:],h[:h.shape[0]//2]), 0  )
    return h


#손실 계산 함수
def distance_loss(hypothesis, broken_image):    
    return torch.dist(hypothesis, broken_image)

#랜덤 이미지 텐서
random_tensor = torch.randn(10000, dtype = torch.float)
random_tensor




lr = 0.8
for i in range(0,20000):
    #자동 미분 기능 on
    random_tensor.requires_grad_(True)
    #이미지에 노이즈 추가
    hypothesis = weird_function(random_tensor)
    #오차 계산
    loss = distance_loss(hypothesis, broken_image)
			생성             원본
    loss.backward()
    #자동 미분 기능 off
    with torch.no_grad():
        random_tensor = random_tensor - lr*random_tensor.grad
    if i % 1000 == 0:
        print('Loss at {} = {}'.format(i, loss.item()))





import tensorflow as tf
pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,
                                                     weights='imagenet')
pretrained_model.summary()



pretrained_model.trainable = False
	추론모드
decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions



# 이미지 전처리 함수
def preprocess(image):
  image = tf.cast(image, tf.float32)
  image = tf.image.resize(image, (224, 224))
  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)
  image = image[None, ...]
  return image

# 레이블 출력 함수
def get_imagenet_label(probs):
  return decode_predictions(probs, top=1)[0][0]


#샘플 이미지
image_raw = tf.io.read_file('d:/images/dog.jpg')
image = tf.image.decode_image(image_raw)
image = preprocess(image)
image_probs = pretrained_model.predict(image)


208
('n02099712', 'Labrador_retriever', 0.41818547)



#적대적 이미지 생성
#입력 이미지에 대한 gradient를 사용하여 원본 이미지에 가하게 될 왜곡 생성
loss_object = tf.keras.losses.CategoricalCrossentropy()
def create_adversarial_pattern(input_image, input_label):
  with tf.GradientTape() as tape:
    tape.watch(input_image)
    prediction = pretrained_model(input_image)
    loss = loss_object(input_label, prediction)
  # 원본과의 손실 계산
  gradient = tape.gradient(loss, input_image)
  signed_grad = tf.sign(gradient)
  return signed_grad



labrador_retriever_index = 208
#label에 대한 원핫인코딩
label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])
label = tf.reshape(label, (1, image_probs.shape[-1]))
# 왜곡된 이미지 패턴 생성
perturbations = create_adversarial_pattern(image, label)
plt.imshow(perturbations[0] * 0.5 + 0.5)  # To change [-1, 1] to [0,1]



#왜곡된 이미지로 인해 이미지 분류 오류 발생
epsilons = [0, 0.01, 0.1, 0.15] # 값이 커질수록 이미지 왜곡이 심해짐
descriptions = [('Epsilon = {:0.3f}'.format(eps) if eps else 'Input') for eps in epsilons]
for i, eps in enumerate(epsilons):
  adv_x = image + eps*perturbations
	  원본     노이즈
  adv_x = tf.clip_by_value(adv_x, -1, 1)  # 픽셀값을 -1 ~ 1 로 조절
  display_images(adv_x, descriptions[i])



import torch
import random
# real 이미지 생성 함수
def generate_real():
    #random.uniform(a,b) a~b 랜덤실수
    real_data = torch.FloatTensor(
        [random.uniform(0.8, 1.0),
         random.uniform(0.0, 0.2),
         random.uniform(0.8, 1.0),
         random.uniform(0.0, 0.2)])
    return real_data


# random 이미지 생성 함수
def generate_random(size):
    # 평균 0, 표준편차 1인 정규분포 난수 생성
    random_data = torch.rand(size)
    return random_data



import torch.nn as nn
import pandas as pd
# 판별모형
class Discriminator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(4, 3),
                     in
            nn.Sigmoid(),
            nn.Linear(3, 1),
                         out
            nn.Sigmoid()
        )
        
        self.loss_function = nn.MSELoss()
        self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)
        self.counter = 0
        self.progress = []
    
    
    def forward(self, inputs):
        return self.model(inputs)
    
    
    def train(self, inputs, targets):
        outputs = self.forward(inputs)
        
        loss = self.loss_function(outputs, targets)
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
            
        if self.counter % 10000 == 0:
            print("counter = ", self.counter)
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()


D = Discriminator()
for i in range(10000):
    # real image
    D.train(generate_real(), torch.FloatTensor([1.0]))
    # fake image
    D.train(generate_random(4), torch.FloatTensor([0.0]))   






print( D.forward( generate_real() ).item() )
print( D.forward( generate_random(4) ).item() )

0.5353667736053467		0.0 ~ 1.0	1
0.40597036480903625				0

# 생성모형
class Generator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(1, 3),
		     in
            nn.Sigmoid(),
            nn.Linear(3, 4),
			 out
            nn.Sigmoid()
        )
        self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)
        self.counter = 0
        self.progress = []
    
    
    def forward(self, inputs):        
        return self.model(inputs)
    
    
    def train(self, D, inputs, targets):
        g_output = self.forward(inputs)
        
        d_output = D.forward(g_output)
        
        loss = D.loss_function(d_output, targets)
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()



D = Discriminator()
G = Generator()
image_list = []
for i in range(10000):
    # 판별모형 학습(true)    
    D.train(generate_real(), torch.FloatTensor([1.0]))
    
    # 판별모형 학습(false)
    D.train(G.forward(torch.FloatTensor([0.5])).detach(), torch.FloatTensor([0.0]))
    
    # 생성모형 학습
    G.train(D, torch.FloatTensor([0.5]), torch.FloatTensor([1.0]))
    
    if i % 1000 == 0:
      image_list.append( G.forward(torch.FloatTensor([0.5])).detach().numpy() )

G.forward(torch.FloatTensor([0.5]))
tensor([0.7969, 0.1691, 0.8461, 0.1848], grad_fn=<SigmoidBackward0>)



















from torch.utils.data import Dataset
import pandas as pd
import matplotlib.pyplot as plt

# dataset class
class MnistDataset(Dataset):
    
    def __init__(self, csv_file):
        self.data_df = pd.read_csv(csv_file, header=None)
    
    
    def __len__(self):
        return len(self.data_df)
    
    def __getitem__(self, index):
        # image target (label)
        label = self.data_df.iloc[index,0]
        target = torch.zeros((10))
        target[label] = 1.0
        
        # image data
        image_values = torch.FloatTensor(self.data_df.iloc[index,1:].values) / 255.0
        
        return label, image_values, target
    
    def plot_image(self, index):
        img = self.data_df.iloc[index,1:].values.reshape(28,28)
        plt.title("label = " + str(self.data_df.iloc[index,0]))
        plt.imshow(img, interpolation='none', cmap='Blues')

# 랜덤 이미지 생성 함수(real)
def generate_random_image(size):
    random_data = torch.rand(size)
    return random_data

# 랜덤 이미지 생성 함수(fake)
def generate_random_seed(size):
    random_data = torch.randn(size)
    return random_data

# 판별모형

import torch.nn as nn
class Discriminator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(784, 200),
                     픽셀
            # 음수이면 기울기 0.02
            nn.LeakyReLU(0.02),
            # 레이어에 대한 정규화
            nn.LayerNorm(200),
            nn.Linear(200, 1),
			   0/1
            nn.Sigmoid()
        )
        
        # binary cross entropy
        self.loss_function = nn.BCELoss()
        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)
        self.counter = 0
        self.progress = []
    
    
    def forward(self, inputs):
        return self.model(inputs)
    
    
    def train(self, inputs, targets):
        outputs = self.forward(inputs.to(DEVICE))
        
        loss = self.loss_function(outputs, targets.to(DEVICE))
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
            
        if self.counter % 10000 == 0:
            print("counter = ", self.counter)
            
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
    
    
    def plot_progress(self):
        df = pd.DataFrame(self.progress, columns=['loss'])
        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))




D = Discriminator().to(DEVICE)
for label, image_data_tensor, target_tensor in mnist_dataset:
    # real data
    D.train(image_data_tensor, torch.FloatTensor([1.0]))
    # fake data
    D.train(generate_random_image(784), torch.FloatTensor([0.0]))



import random

# test real data
for i in range(4):
  image_data_tensor = mnist_dataset[random.randint(0,60000)][1]
  print( D.forward( image_data_tensor.to(DEVICE) ).item() )
  
# test fake data
for i in range(4):
  print( D.forward( generate_random_image(784).to(DEVICE) ).item() )



9.666615598258321e-12
8.75574265868373e-12
9.873511730429385e-12
8.923037655983457e-12


		100x100

# 생성모델
class Generator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(100, 200),
		      input
            nn.LeakyReLU(0.02),
            nn.LayerNorm(200),
            nn.Linear(200, 784),
            nn.Sigmoid()
        )
        
        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)
        self.counter = 0
        self.progress = []
        
    
    
    def forward(self, inputs):        
        return self.model(inputs.to(DEVICE))
    
    
    def train(self, D, inputs, targets):
        g_output = self.forward(inputs.to(DEVICE))
        
        d_output = D.forward(g_output)
        
        loss = D.loss_function(d_output, targets.to(DEVICE))
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
            
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
    
    
    def plot_progress(self):
        df = pd.DataFrame(self.progress, columns=['loss'])
        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))


G = Generator().to(DEVICE)
output = G.forward(generate_random_seed(100))
784
img = output.cpu().detach().numpy().reshape(28,28)
plt.imshow(img, cmap='Blues')
plt.show()



D = Discriminator().to(DEVICE)
G = Generator().to(DEVICE)
epochs = 4
for epoch in range(epochs):
  print ("epoch = ", epoch + 1)
  for label, image_data_tensor, target_tensor in mnist_dataset:
	답     이미지픽셀              1
    # 판별모형 훈련(true)
    D.train(image_data_tensor, torch.FloatTensor([1.0]))
		실제이미지		1
    
    # 판별모형 훈련(false)
    D.train(G.forward(generate_random_seed(100)).detach(), torch.FloatTensor([0.0]))
			랜덤이미지 				0
    
    # 생성모형 훈련
    G.train(D, generate_random_seed(100), torch.FloatTensor([1.0]))
			랜덤이미지			1




torch.save(G,'final_mnist_G.h5')



import torch
USE_CUDA = torch.cuda.is_available()
		gpu 사용가능 여부
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")


G=torch.load('final_mnist_G.h5')
G.to(DEVICE)
Generator(
  (model): Sequential(
    (0): Linear(in_features=100, out_features=200, bias=True)
    (1): LeakyReLU(negative_slope=0.02)
    (2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
    (3): Linear(in_features=200, out_features=784, bias=True)
    (4): Sigmoid()
  )
)

#학습된 가중치 확인
print(G.model[3].weight[0][:10])
print(G.model[3].bias[:10])



import os    
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import matplotlib.pyplot as plt
count = 0
f, axarr = plt.subplots(2,3, figsize=(12,6))
for i in range(2):
    for j in range(3):
        output = G.forward(generate_random_seed(100))
			생성모델	랜덤이미지
        img = output.cpu().detach().numpy().reshape(28,28)
        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')
        pass
    pass

seed1 = generate_random_seed(100)
out1 = G.forward(seed1)
img1 = out1.cpu().detach().numpy().reshape(28,28)
plt.imshow(img1, cmap='Blues')
plt.show()




count = 0
f, axarr = plt.subplots(3,4, figsize=(10,6))
for i in range(3):
    for j in range(4):
        seed = seed1 + (seed2 - seed1)/11 * count
        output = G.forward(seed)
        img = output.cpu().detach().numpy().reshape(28,28)
        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')
        count = count + 1
        pass
    pass





from tensorflow.keras.datasets import mnist
(train_images, train_labels), (_, _) = mnist.load_data()


train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
train_images = (train_images - 127.5) / 127.5 # [-1, 1]로 정규화
		 0~255


import tensorflow as tf
# 미니배치로 나누고 섞음
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)






# 생성 모형
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, BatchNormalization
def make_generator_model():
    model = Sequential()
    # use_bias=F , bias를 생성하지 않음
    # BatchNormalization으로 평균값이 0이므로 bias를 훈련시킬 필요가 없음
    model.add(Dense(7*7*256, use_bias=False, input_shape=(100,)))
						픽셀 100
    model.add(BatchNormalization())
		평균 0, 표준편차 1
    model.add(LeakyReLU())  #기본값 0.01
    model.add(Reshape((7, 7, 256))) # 출력된 값을 reshape
    # 역합성곱층
    model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))    
    model.add(BatchNormalization())
    model.add(LeakyReLU())
    model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    model.add(BatchNormalization())
    model.add(LeakyReLU())
    model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))
    return model





# BatchNormalization 설명
from matplotlib import pyplot as plt 

model = Sequential([
    BatchNormalization()
])
model.compile()
img = plt.imread("d:/images/apple.jpg")
img_tensor = tf.convert_to_tensor(img, dtype="float32")
		이미지 픽셀(넘파이) => 텐서
bn1 = model(img_tensor, training=True)
bn1_numpy = bn1.numpy()
print(bn1_numpy)
plt.imshow(bn1_numpy)


# 입력 이미지 크기: 4x4, 채널: 3 
input_shape = (4, 4, 3)

layer = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), input_shape=input_shape)

a = tf.random.normal(shape=(1, *input_shape))  
b = layer(a)
print(a.shape)

print(b.shape)




#판별 모형
from tensorflow.keras.layers import Conv2D, Dropout, Flatten
def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same',
                                     input_shape=[28, 28, 1]))
    model.add(LeakyReLU())
    model.add(Dropout(0.3))
    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(LeakyReLU())
    model.add(Dropout(0.3))
    model.add(Flatten())
    model.add(Dense(1))		0.0~1.0
    return model



discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print (decision)


















