Django
	게시판
	React
	CentOS 배포
	Ubuntu 배포

OpenCV(컴퓨터비전)	

이미지 분석
	생성모델

강화학습

9/18(월)부터 3차 프로젝트 시작
10/13(금) 3차 프로젝트 발표회(예정), 업체 참관/현장 면접
10/17(화) 수료
10/24(화) 종강

# 날짜 포맷 변경을 위한 모듈 로딩
from django.conf.locale.ko import formats as ko_formats
# 날짜 포맷 설정
ko_formats.DATETIME_FORMAT = 'Y-m-d G:i:s'
			     연 월 일 시 분 초



        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'pyweb', # DB
        'USER': 'web', # id
        'PASSWORD': '1234', # password
        'HOST': 'localhost', # host
        'PORT': '3306', # port






from django.db import models
from datetime import datetime


class Board(models.Model):
    idx = models.AutoField(primary_key=True)
	글번호	자동증가
    writer = models.CharField(null=False, max_length=50)
	이름
    title = models.CharField(null=False, max_length=120)
	제목
    hit = models.IntegerField(default=0)
	조회수
    content = models.TextField(null=False)
	본문
    post_date = models.DateTimeField(default=datetime.now, blank=True)
    filename = models.CharField(null=True, blank=True, default="", max_length=500)
	파일이름
    filesize = models.IntegerField(default=0)
	파일크기
    down = models.IntegerField(default=0)
	다운로드 횟수

    def hit_up(self):
        self.hit += 1

    def down_up(self):
        self.down += 1

	글번호	댓글번호
	1	1
		2
		3
	2	4
		5
		6


class Comment(models.Model):
    idx = models.AutoField(primary_key=True)
	일련번호
    board_idx = models.IntegerField(null=False)
	부모글번호
    writer = models.CharField(null=False, max_length=50)
    content = models.TextField(null=False)
    post_date = models.DateTimeField(default=datetime.now, blank=True)



admin.site.register(Board)
관리자  사이트 등록     테이블





DELIMITER $$
drop procedure if exists loopInsert$$
삭제		존재하면
create procedure loopInsert()
begin
  declare i int default 1;	
	변수명 자료형
  delete from board_board;
  while i <= 991 do
    insert into board_board (IDX, writer, TITLE, CONTENT, hit, post_date,filesize,down)
    values (i, concat('kim',i), concat('제목',i), concat('내용 ',i),0,now(),0,0);
    set i = i + 1;
  end while;
end$$

DELIMITER $$

call loopInsert
	프로시저이름






urlpatterns = [
    path('admin', admin.site.urls),
    path('', views.list),
    path('write', views.write),
    path('insert', views.insert),
    path('detail', views.detail),
    path('update', views.update),
    path('delete', views.delete),
    path("download", views.download),
    path("reply_insert", views.reply_insert)
]


import math
import os
from django.shortcuts import redirect, render
from django.db.models import Q
from django.http import HttpResponse, HttpResponseRedirect
from board.models import Board, Comment
from urllib.parse import quote

UPLOAD_DIR = "c:/upload/"


def list(request):
    try:
        search_option = request.POST["search_option"]
    except:
        search_option = "writer"

    try:
        search = request.POST["search"]
    except:
        search = ""

    boardCount = Board.objects.count()
			레코드 개수
    try:
        start = int(request.GET['start'])
    except:
        start = 0

    page_size = 10  # 페이지당 게시물수
    page_list_size = 10  # 한 화면에 표시할 페이지의 갯수
    end = start + page_size
    total_page = math.ceil(boardCount / page_size)
			올림
    current_page = math.ceil((start + 1) / page_size)
    start_page = math.floor((current_page - 1) / page_list_size) * page_list_size + 1
			버림
    end_page = start_page + page_list_size - 1
    if total_page < end_page:
        end_page = total_page
    if start_page >= page_list_size:
        prev_list = (start_page - 2) * page_size
    else:
        prev_list = 0
    if total_page > end_page:
        next_list = end_page * page_size
    else:
        next_list = 0

    if search_option == "all": 이름+내용+제목
        boardList = Board.objects.filter(
            Q(writer__contains=search) | Q(title__contains=search)
		필드명__contains=키워드
            | Q(content__contains=search)).order_by("-idx")[start:end]
    elif search_option == "writer":
        boardList = \
            Board.objects.filter(writer__contains=search).order_by("-idx")[start:end]
    elif search_option == "title":
        boardList = \
            Board.objects.filter(title__contains=search).order_by("-idx")[start:end]
    elif search_option == "content":
        boardList = \
            Board.objects.filter(content__contains=search).order_by("-idx")[start:end]

    links = []
    for i in range(start_page, end_page + 1):
        page = (i - 1) * page_size
        links.append("<a href='?start=" + str(page) + "'>" + str(i) + "</a>")

    return render(request, "list.html",
                  {"boardList": boardList, "search_option": search_option,
                   "search": search,
                   "range": range(start_page - 1, end_page), "start_page": start_page,
                   "end_page": end_page,
                   "page_list_size": page_list_size, "total_page": total_page,
                   "prev_list": prev_list,
                   "next_list": next_list, "links": links})


def write(request):
    return render(request, "write.html")


def insert(request):
    fname = ""
    fsize = 0
    if "file" in request.FILES:
        file = request.FILES["file"]
        fname = file._name

        with open("%s%s" % (UPLOAD_DIR, fname), "wb") as fp:
            for chunk in file.chunks():
                fp.write(chunk)

        fsize = os.path.getsize(UPLOAD_DIR + fname)

    row = Board(writer=request.POST["writer"], title=request.POST["title"],
                content=request.POST["content"],
                filename=fname, filesize=fsize)

    row.save()

    return redirect("/")


def detail(request):
    # 조회수 증가 처리
    id = request.GET["idx"]
    row = Board.objects.get(idx=id)
    row.hit_up()
    row.save()

    commentList = Comment.objects.filter(board_idx=id).order_by("idx")

    filesize = "%.2f" % (row.filesize / 1024)
    return render(request, "detail.html", {"row": row, "filesize": filesize,
                                           "commentList": commentList})


def update(request):
    id = request.POST['idx']
    row_src = Board.objects.get(idx=id)

    fname = row_src.filename  # 수정 전의 첨부파일 이름
    fsize = row_src.filesize  # 수정 전의 첨부파일 크기
    hit = row_src.hit  # 수정 전의 조회수
    down = row_src.down  # 수정 전의 다운로드 횟수
    if "file" in request.FILES:
        file = request.FILES["file"]
        fname = file._name

        with open("%s%s" % (UPLOAD_DIR, fname), "wb") as fp:
            for chunk in file.chunks():
                fp.write(chunk)

        fsize = os.path.getsize(UPLOAD_DIR + fname)

    row_new = Board(idx=id, writer=request.POST["writer"], title=request.POST["title"],
                    content=request.POST["content"],
                    filename=fname, filesize=fsize, hit=hit, down=down)
    row_new.save()
    return redirect("/")


def delete(request):
    id = request.POST["idx"]
    Board.objects.get(idx=id).delete()
    return redirect("/")


def download(request):
    id = request.GET['idx']
    row = Board.objects.get(idx=id)
    path = UPLOAD_DIR + row.filename

    filename = os.path.basename(path)  # 디렉토리를 제외한 파일이름
    # filename = filename.encode("utf-8")
    filename = quote(filename)  # 한글,특수문자 인코딩 처리

    with open(path, 'rb') as file:
        response = HttpResponse(file.read(), content_type="application/octet-stream")
        # UTF-8 뒤에 작은 따옴표 2개
        response["Content-Disposition"] = \
            "attachment; filename*=UTF-8''{0}".format(filename)
        row.down_up()
        row.save()
        return response


def reply_insert(request):
    id = request.POST["idx"]
    row = Comment(board_idx=id, writer=request.POST["writer"],
                  content=request.POST["content"])

    row.save()
    # redirect 함수 대신 HttpResponseRedirect 함수를 사용해야 함
    return HttpResponseRedirect("detail?idx=" + id)
import cv2
import numpy as np
#음각
mask1 = np.array([[-1, 0, 0],
                  [0, 0, 0],
                  [0, 0, 1]])
#양각
mask2 = np.array([[1, 1, 1],
                  [1, -8, 1],
                  [1, 1, 1]])
# 원본, 깊이, 마스크
out1 = cv2.filter2D(gray, -1, mask1)
out2 = cv2.filter2D(gray, -1, mask2)



import cv2
import numpy as np
img = cv2.imread('d:/images/plane_256x256.jpg')
rows, cols = img.shape[:2]
H     W    C
# 마스크 생성, 원래 이미지 보다 2픽셀 크게
mask = np.zeros((rows+2, cols+2), np.uint8)
# 채울 색상
newVal = (255,255,255)
# 최소 최대 차이 값
loDiff, upDiff = (10,10,10), (10,10,10)

def onMouse(event, x, y, flags, param):
    global mask, img
    if event == cv2.EVENT_LBUTTONDOWN:
        seed = (x,y)
        # 연속 영역에 같은 색상을 채우는 함수
        # cv2.floodFill(입력 영상, 입력 영상보다 2X2 픽셀이 더 큰 배열, seed, 채우기에 사용할 색상 값, 채우기 진행을 결정할 최소차이값, 채우기 진행을 결정할 최대 차이값, 채우기방식)        
        retval = cv2.floodFill(img, mask, seed, newVal, loDiff, upDiff)
        cv2.imshow('img', img)
        
cv2.imshow('img', img)
cv2.setMouseCallback('img', onMouse)
		    이미지객체   마우스이벤트함수
cv2.waitKey(0)
cv2.destroyAllWindows()


import numpy as np
# 합성할 이미지
mask = np.full_like(img1, 255)
# 합성 대상 좌표 계산(img2의 중앙)
height, width = img2.shape[:2]
center = (width//2, height//2)


# seamlessClone
# seam 경계 less 없는 clone 복제, 부드럽게 이미지를 합성하는 함수
normal = cv2.seamlessClone(img1, img2, mask, center, cv2.NORMAL_CLONE)
plt.imshow(normal)
plt.axis("off")
plt.show()
# 꽃은 선명하지만 주변 이미지가 흐려짐




# cv2.GaussianBlur(이미지, 커널사이즈, x방향시그마)
img1_blue = cv2.GaussianBlur(img1, (3,3), 0)
# 소벨 필터, Sobel(이미지, cv2.FILTER_SCHARR, x미분차수, y미분차수, 커널사이즈)
res1 = cv2.Sobel(img1, cv2.FILTER_SCHARR, 1, 0, ksize=3)
# 샤를 필터, Scharr(이미지, cv2.FILTER_SCHARR, x미분차수, y미분차수, 커널사이즈)
res2 = cv2.Scharr(img1_blue, cv2.CV_32FC1, 0, 1)
res3 = cv2.Laplacian(img1_blue, cv2.CV_32FC1)
#cv2.Canny(이미지, 하단임계값, 상단임계값, 커널사이즈, 정규화옵션)
res4 = cv2.Canny(img1, 50, 200, apertureSize=5, L2gradient=True)



# contour : 동일한 픽셀값을 가지고 있는 영역의 경계선 정보, 윤곽선, 외형 파악
import cv2
import numpy as np
img = cv2.imread('d:/images/hand.jpg')
img2 = img.copy()
	복사
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
		흑백으로
ret, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
		이진화         기준  최대
# 컨투어 찾기와 그리기
contours, heiarchy = cv2.findContours(th, cv2.RETR_EXTERNAL, \
                                         cv2.CHAIN_APPROX_SIMPLE)[-2:]
cntr = contours[0]
cv2.drawContours(img, [cntr], -1, (0, 255,0), 1)
# convexHull : 2차원 평면상의 여러 포인트를 이용하여 볼록 다각형을 만드는 알고리즘
hull = cv2.convexHull(cntr) #좌표 기준
cv2.drawContours(img2, [hull], -1, (0,255,0), 1)
print(cv2.isContourConvex(cntr), cv2.isContourConvex(hull))
hull2 = cv2.convexHull(cntr, returnPoints=False) # 인덱스 기준
# 볼록 선체 결함 찾기
defects = cv2.convexityDefects(cntr, hull2)
# 볼록 선체 결함 순회
for i in range(defects.shape[0]):
    # 시작, 종료, 가장 먼 지점, 거리
    startP, endP, farthestP, distance = defects[i, 0]
    # 가장 먼 지점의 좌표
    farthest = tuple(cntr[farthestP][0])
    dist = distance/256.0
    if dist > 1 :
        cv2.circle(img2, farthest, 3, (0,0,255), -1)
        
cv2.imshow('contour', img)
cv2.imshow('convex hull', img2)
cv2.waitKey(0)
cv2.destroyAllWindows()

import cv2
dst = src.copy()
gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
#cv2.HoughCircles(이미지, 검출 방법, 해상도 비율, 최소 거리, 캐니 엣지 임계값, 중심 임계값, 최소 반지름, 최대 반지름)
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 100, param1 = 250, param2 = 10, minRadius = 80, maxRadius = 120)
#circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 100, param1 = 250, param2 = 10, minRadius = 120, maxRadius = 130)

for i in circles[0]:
    #원 그리기 함수
    cv2.circle(dst, (int(i[0]), int(i[1])), int(i[2]), (255, 255, 255), 5)



import matplotlib.pyplot as plt
import numpy as np
import h5py
with h5py.File('d:/data/celeba/celeba_aligned_small.h5py', 'r') as fp:  
  dataset = fp['d:/data/celeba/img_align_celeba']
  image = np.array(dataset['11.jpg'])
  plt.imshow(image, interpolation='none')  






self.dataset = self.file_object['d:/data/celeba/img_align_celeba']     


import torch
print(torch.cuda.is_available())
	gpu 사용가능
print(torch.cuda.current_device())
print(torch.cuda.device_count())
print(torch.cuda.get_device_name(0))
# True
# 0
# 1
# NVIDIA GeForce GTX 1050 Ti






#데이터셋 클래스
from torch.utils.data import Dataset
import h5py
import numpy as np  
import matplotlib.pyplot as plt
class CelebADataset(Dataset):
    
    def __init__(self, file):
        self.file_object = h5py.File(file, 'r')
        self.dataset = self.file_object['d:/data/celeba/img_align_celeba']        
    
    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, index):
        if (index >= len(self.dataset)):
          raise IndexError()
        img = np.array(self.dataset[str(index)+'.jpg'])
        return torch.cuda.FloatTensor(img) / 255.0
    
    def plot_image(self, index):
        plt.imshow(np.array(self.dataset[str(index)+'.jpg']), interpolation='nearest')



# 랜덤 데이터 생성 함수
def generate_random_image(size):
    random_data = torch.rand(size)
    return random_data

def generate_random_seed(size):
    random_data = torch.randn(size)
    return random_data



import torch.nn as nn
class View(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.shape = shape
    def forward(self, x):
        return x.view(self.shape) 



# 판별 모형
import pandas as pd
class Discriminator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            View(218*178*3),
            
            nn.Linear(3*218*178, 100),
            nn.LeakyReLU(),
            
            nn.LayerNorm(100),
            
            nn.Linear(100, 1),	0.0~1.0 0/1
            nn.Sigmoid()
        )
        
        self.loss_function = nn.BCELoss()
        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)
        self.counter = 0
        self.progress = []
    
    def forward(self, inputs):
        return self.model(inputs)
    
    
    def train(self, inputs, targets):
        outputs = self.forward(inputs)
        
        loss = self.loss_function(outputs, targets)
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
            
        if self.counter % 1000 == 0:
            print("counter = ", self.counter)
            
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
    
    def plot_progress(self):
        df = pd.DataFrame(self.progress, columns=['loss'])
        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))



%%time
#판별 모형 테스트(오래 걸림, 40~50분)
D = Discriminator()
D.to(device)
for image_data_tensor in celeba_dataset:
    # 실제 데이터
    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))
		실제데이터		1
    # 가짜 데이터
    D.train(generate_random_image((218,178,3)), torch.cuda.FloatTensor([0.0]))
		가짜데이터					0



# 판독모델 테스트
import random
# test real data
for i in range(4):
  image_data_tensor = celeba_dataset[random.randint(0,20000)]
  print( D.forward( image_data_tensor ).item() )

# test fake data
for i in range(4):
  print( D.forward( generate_random_image((218,178,3))).item() )


0.9998000264167786
0.9997207522392273
0.998004138469696
0.9998475313186646
0.0001484931563027203
0.00014357836334966123
0.00013114555622451007
0.00012913745013065636

# 생성 모델
class Generator(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(100, 3*10*10),
			100개 랜덤숫자 =>
            nn.LeakyReLU(),
            
            nn.LayerNorm(3*10*10),
            
            nn.Linear(3*10*10, 3*218*178),
            
            nn.Sigmoid(),
            View((218,178,3))
        )
        
        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)
        self.counter = 0
        self.progress = []
    
    def forward(self, inputs):        
        return self.model(inputs)
    
    def train(self, D, inputs, targets):
        g_output = self.forward(inputs)
        
        d_output = D.forward(g_output)
        
        loss = D.loss_function(d_output, targets)
        self.counter += 1
        if self.counter % 10 == 0:
            self.progress.append(loss.item())
        self.optimiser.zero_grad()
        loss.backward()
        self.optimiser.step()
    
    def plot_progress(self):
        df = pd.DataFrame(self.progress, columns=['loss'])
        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))


#생성모델 테스트
G = Generator()
G.to(device)
output = G.forward(generate_random_seed(100))
img = output.detach().cpu().numpy()
plt.imshow(img, interpolation='none', cmap='Blues')




%%time
# 판독모형, 생성모형 생성
D = Discriminator()
D.to(device)
G = Generator()
G.to(device)
epochs = 2
for epoch in range(epochs):
  print ("epoch = ", epoch + 1)
  for image_data_tensor in celeba_dataset:
    # 판별모형 훈련(true)
    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))
    		실제이미지		1
    # 판별모형 훈련(false)
    D.train(G.forward(generate_random_seed(100)).detach(), torch.cuda.FloatTensor([0.0]))
			가짜이미지				0
    
    # 생성모형 훈련
    G.train(D, generate_random_seed(100), torch.cuda.FloatTensor([1.0]))
			가짜이미지			1


G=torch.load('d:/data/models/final_celeba_G.h5')
G.to(device)


import os    
os.environ['KMP_DUPLICATE_LIB_OK']='True'
import matplotlib.pyplot as plt
count = 0
f, axarr = plt.subplots(2,3, figsize=(16,8))
for i in range(2):
    for j in range(3):
        output = G.forward(generate_random_seed(100))
        img = output.detach().cpu().numpy()
        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')
        pass
    pass


# GPU 메모리 사용량
torch.cuda.memory_allocated(device) / (1024*1024*1024)




image_height = 150  
image_width = 150    
batch_size = 10    
no_of_epochs  = 20  


	데이터 증강
train_datagen = ImageDataGenerator(
        rescale=1./255,         # 픽셀값 0~1 변환
        rotation_range=40,      # 40도까지 회전
        width_shift_range=0.2,  # 20%까지 좌우 이동
        height_shift_range=0.2, # 20%까지 상하 이동
        shear_range=0.2,        # 20%까지 기울임
        zoom_range=0.2,         # 20%까지 확대
        horizontal_flip=True,   # 좌우 뒤집기
    )
train_generator = train_datagen.flow_from_directory(
    'd:/data/CatDog/train',
    batch_size=10,      
    class_mode='binary', # binary, categorical
		이진분류
    target_size=(image_width, image_height))
test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(
    'd:/data/CatDog/test',
    batch_size=10,
    class_mode='binary',
    target_size=(image_width, image_height))


for X_batch, y_batch in ImageDataGenerator(rescale=1./255).flow_from_directory('d:/data/CatDog/train',batch_size=16, class_mode='binary', target_size=(150, 150)):
    plt.figure(figsize=(20,20))
    for i in range(0, 16):
        ax = plt.subplot(4, 4, i+1)
        ax.set_title(findKey(train_generator.class_indices, y_batch[i]))  
        plt.imshow((X_batch[i].reshape(150, 150, 3)*255).astype(np.uint8))
    plt.show()
    break




model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=
		필터수  사이즈
(image_height,image_width, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu'))
model.add(Dense(1, activation='sigmoid'))	
model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])
model.summary()

monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience=5)
		조기학습종료		기준		
history = model.fit_generator(generator=train_generator,
                    steps_per_epoch=2000//batch_size,
                    epochs=no_of_epochs,
                    validation_data=test_generator,
                    validation_steps=800//batch_size,
                    callbacks=[monitor_val_acc])  



predictions = model.predict(test_generator, steps=16, verbose=1)
print(predictions.shape)
print(predictions[0])
print(predictions[1])

[[0.31222907]	0
 [0.8515092 ]	1
 [0.60319895]	1
 [0.93306655]	1
 [0.26491064]	0
 [0.93417805]
 [0.14175336]
 [0.01790096]
 [0.7367327 ]
 [0.56026965]
 [0.937665  ]
 [0.2881018 ]
 [0.15645929]





total_images_train_normal = os.listdir('d:/data/chest_xray/train/NORMAL/') # 정상
total_images_train_pneumonia = os.listdir('d:/data/chest_xray/train/PNEUMONIA/') #폐렴



train_datagen = ImageDataGenerator(rescale=1./255,     # 픽셀 값 0.0~1.0
                                   rotation_range=15,  # 15도까지 회전
                                   shear_range=0.2,    # 20%까지 기울임
                                   zoom_range=0.2      # 20%까지 확대
                                   )
val_datagen = ImageDataGenerator(rescale=1./255)    




training_set = train_datagen.flow_from_directory('d:/data/chest_xray/chest_xray/train',
                                                 target_size=(image_width, image_height),
                                                 batch_size=batch_size,
                                                 class_mode='binary')
test_set = val_datagen.flow_from_directory('d:/data/chest_xray/test',
                                            target_size=(image_width, image_height),
                                            batch_size=batch_size,
                                            class_mode='binary')
val_set = val_datagen.flow_from_directory('d:/data/chest_xray/val',
                                            target_size=(image_width, image_height),
                                            batch_size=1,
                                            shuffle=False,
                                            class_mode='binary')

array([[0.31578273],	0
       [0.07466196],	0
       [0.58022404],	1
       [0.61079526],	1
       [0.98853207],	1
       [0.32162386],
       [0.7854039 ],
       [0.12852035],
       [0.98196745],
       [0.9696917 ],
       [0.9896417 ],
       [0.8690185 ],
       [0.94330794],
       [0.9973283 ],
       [0.1264934 ],
       [0.9844939 ]]

train_datagen = ImageDataGenerator(
    zoom_range=0.2,        
    rotation_range=10,    
    horizontal_flip=True,
    rescale=1./255)      
train_generator = train_datagen.flow_from_directory(
    'D:/data/intel-image-classification/seg_train/seg_train',
    batch_size=1,      
    class_mode='sparse',
		원핫인코딩 x => sparse	0~5
    target_size=(150, 150))  
test_datagen = ImageDataGenerator(
    zoom_range=0.2,        
    rotation_range=10,    
    horizontal_flip=True,  
    rescale=1./255)      
test_generator = test_datagen.flow_from_directory(
    'D:/data/intel-image-classification/seg_test/seg_test',
    batch_size=1,
    class_mode='sparse',
    target_size=(150, 150))

import numpy as np
batch_size=1
n_img = train_generator.n
steps = n_img // batch_size
X_train, y_train = [], []
for i in range(steps):
    a, b = train_generator.next()
    X_train.extend(a)
    y_train.extend(b)
    if i > 500:
        break
    
X_train = np.asarray(X_train)
y_train = np.asarray(y_train)
X_train.shape, y_train.shape





model = Sequential()
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3), name="conv1"))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name="conv2"))
model.add(MaxPooling2D(pool_size=(3, 3), name="maxpool1"))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', name="conv3"))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', name="conv4"))
model.add(MaxPooling2D(pool_size=(3, 3), name="maxpool2"))
model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', name="conv5"))
model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', name="conv6"))
model.add(MaxPooling2D(pool_size=(3, 3), name="maxpool3"))
model.add(Flatten())
model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001)))
model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001)))
model.add(Dropout(0.25))
model.add(Dense(6, activation='softmax'))

	0~5

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=Adam(learning_rate=0.0001),
              metrics=['accuracy'])
model.summary()

def get_images(directory):
    Images = []
    pred_img_cnt = 25  
    i = 0
    for image_file in os.listdir(directory):        
        i += 1
        if i > pred_img_cnt: break
        else:
            image = cv2.imread(directory+r'/'+image_file)
            image = cv2.resize(image,(150,150))          
            Images.append(image)
    return Images


[0.29470098 0.05112666 0.03281317 0.00845189 0.0187523  0.59415495]	
	0	1	2		3	4		5
5



	CLI - Command Line Interface
	GUI - Graphic User Interface


ResourceExhaustedError                    

/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]





1/1 [==============================] - 4s 4s/step
(0.828591)Tibetan_mastiff
(0.035680212)malamute
(0.033451438)Newfoundland
(0.015547171)collie
(0.0139080705)Siberian_husky





import cv2 as cv
import numpy as np
import tensorflow as tf
import pickle
import sys
from PyQt5.QtWidgets import *
cnn=tf.keras.models.load_model('d:/data/models/cnn_for_stanford_dogs.h5')    
dog_species=pickle.load(open('d:/data/models/dog_species_names.txt','rb'))    
        
class DogSpeciesRecognition(QMainWindow):
    def __init__(self) :
        super().__init__()
        self.setGeometry(200,200,700,100)
      
        fileButton=QPushButton('open image',self)
        recognitionButton=QPushButton('classification',self)
        quitButton=QPushButton('quit',self)
        
        fileButton.setGeometry(10,10,100,30)
				x y width height
        recognitionButton.setGeometry(110,10,100,30)
        quitButton.setGeometry(510,10,100,30)
        
        fileButton.clicked.connect(self.pictureOpenFunction)
		버튼 클릭			함수
        recognitionButton.clicked.connect(self.recognitionFunction)                        
        quitButton.clicked.connect(self.quitFunction)
        
    def pictureOpenFunction(self):
        fname=QFileDialog.getOpenFileName(self,'강아지 사진 읽기','./')          
        self.img=cv.imread(fname[0])
        if self.img is None: sys.exit('파일을 찾을 수 없습니다.')  
        
        cv.imshow('Dog image',self.img)          
        
    def recognitionFunction(self):
        x=np.reshape(cv.resize(self.img,(224,224)),(1,224,224,3))    
        res=cnn.predict(x)[0]    
        top5=np.argsort(-res)[:5]
		분류결과 내림차순
        top5_dog_species_names=[dog_species[i] for i in top5]
        for i in range(5):
            prob='('+str(res[top5[i]])+')'
            name=str(top5_dog_species_names[i]).split('-')[1]
            print(prob+name)
        cv.imshow('Dog image',self.img)  
                
    def quitFunction(self):
        cv.destroyAllWindows()        
        self.close()
              
app=QApplication(sys.argv)
win=DogSpeciesRecognition()
win.show()
app.exec_()



Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools

https://aka.ms/vs/15/release/VC_redist.x64.exe



age_list = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']  # 나이 분류 구간 정의
gender_list = ['Male','Female']  # 성별 구분 정의




# 얼굴을 감지하는 detector
detector = dlib.get_frontal_face_detector()      
# 나이를 감지하는 detector
age_detector = cv2.dnn.readNetFromCaffe(          
               'd:/data/models/deploy_age.prototxt',
               'd:/data/models/age_net.caffemodel')
# 성별을 감지하는 detector        
gender_detector = cv2.dnn.readNetFromCaffe(      
               'd:/data/models/deploy_gender.prototxt',
               'd:/data/models/gender_net.caffemodel')
img_list = glob.glob('d:/data/age_gender/*.jpg') 



import matplotlib.pyplot as plt
import numpy as np
for img_path in img_list:
  image = cv2.imread(img_path)  
  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
  faces = detector(gray, 1)  # detector 에 의해 얼굴 감지
  print("Number of faces detected: {}".format(len(faces)))
  for face in faces:
    # boxing 좌표
    x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()  
    # 이미지에서 얼굴 영역만 copy
    face_img = image[y1:y2, x1:x2].copy()  
    blob = cv2.dnn.blobFromImage(face_img, scalefactor=1, size=(227, 227),
           mean=(78.4263377603, 87.7689143744, 114.895847746), swapRB=False, crop=False)
    # predict age
    age_detector.setInput(blob)
    age_preds = age_detector.forward()
    age = age_list[age_preds[0].argmax()]
    # predict gender
    gender_detector.setInput(blob)
    gender_preds = gender_detector.forward()
    gender = gender_list[gender_preds[0].argmax()]
    cv2.rectangle(image, (x1, y1), (x2, y2), (255,255,255), 2)
    overlay_text = '%s %s' % (gender, age)
    cv2.putText(image, overlay_text, org=(x1, y1), fontFace=cv2.FONT_HERSHEY_SIMPLEX,
                fontScale=1, color=(0,0,0), thickness=10)
    cv2.putText(image, overlay_text, org=(x1, y1),
                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255,255,255), thickness=2)
  image=cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)
  plt.figure()
  plt.imshow(image)
  plt.show()  


import cv2 as cv
import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input,decode_predictions
model=ResNet50(weights='imagenet')
img=cv.imread('d:/images/rabbit.jpg')
x=np.reshape(cv.resize(img,(224,224)),(1,224,224,3))  
x=preprocess_input(x)
preds=model.predict(x)
top5=decode_predictions(preds,top=5)[0]
print('예측 결과:',top5)
for i in range(5):
    cv.putText(img,top5[i][1]+':'+str(top5[i][2]),(10,20+i*20),cv.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),1)
    
cv.imshow('Recognition result',img)
cv.waitKey()
cv.destroyAllWindows()




	centos.org



	CentOS-7-x86_64-DVD-2009.iso    












