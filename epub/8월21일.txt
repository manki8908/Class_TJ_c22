PyTorch

자연어 처리 프로젝트(2차 프로젝트)
	주제 선정
	데이터 수집, 전처리
	기계학습 모형, 평가
	응용프로그램에 배포
	발표 준비




import torch
# Default CUDA device
cuda = torch.device('cuda')
			gpu
# 텐서 자료를 gpu에 저장
a = torch.tensor([1, 2], device=cuda)
	cpu,gpu

b = torch.tensor([1, 2]).cuda()
c = torch.tensor([1, 2]).to(device=cuda)
print(a)
print(b)
print(c)




import torch
# 학습용 데이터를 텐서로 변환
		cpu,gpu
X_train = torch.from_numpy(X_train).float()
		memory=>gpu
y_train = torch.from_numpy(y_train).long()
				정수
# 검증용 데이터를 텐서로 변환
X_test = torch.from_numpy(X_test).float()
y_test = torch.from_numpy(y_test).long()


#텐서를 gpu로 옮기고
X_train=X_train.cuda() gpu로 이동
		.cpu() cpu로 이동
y_train=y_train.cuda()
X_test=X_test.cuda()
y_test=y_test.cuda()


from torch.utils.data import DataLoader, TensorDataset
# 독립변수와 종속변수의 텐서를 합침
train = TensorDataset(X_train, y_train)
print(train[0])
# 미니배치로 분할
train_loader = DataLoader(train, batch_size=16, shuffle=True)
				미니배치


(tensor([1.2370e+01, 1.2100e+00, 2.5600e+00, 1.8100e+01, 9.8000e+01, 2.4200e+00,
        2.6500e+00, 3.7000e-01, 2.0800e+00, 4.6000e+00, 1.1900e+00, 2.3000e+00,
        6.7800e+02], device='cuda:0'), tensor(1, device='cuda:0'))




import torch.nn as nn
import torch.nn.functional as F
# 신경망 구성
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(13, 96) # input 13, output 96
			    in   out
        self.fc2 = nn.Linear(96, 72)
        self.fc3 = nn.Linear(72, 64)
        self.fc4 = nn.Linear(64, 32)
        self.fc5 = nn.Linear(32, 16)
        self.fc6 = nn.Linear(16, 3)
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.relu(self.fc4(x))
        x = F.relu(self.fc5(x))
        x = self.fc6(x)
        return F.log_softmax(x, dim=0)

# 인스턴스 생성
model = Net().cuda()
	모델=>gpu



import torch.optim as optim
from torch.autograd import Variable

# 손실함수 객체
criterion = nn.CrossEntropyLoss()
# 최적화함수
optimizer = optim.SGD(model.parameters(), lr=0.001)
		확률적 경사 하강법		학습률
# 학습 시작
for epoch in range(500):
    total_loss = 0
	손실 총합
    for train_x, train_y in train_loader:
		미니배치 16
        # 계산 그래프 구성
        train_x, train_y = Variable(train_x), Variable(train_y)
        #텐서를 gpu로 이동시킴
        train_x=train_x.cuda()
        train_y=train_y.cuda()        
        # 경사 초기화
        optimizer.zero_grad()
		가중치 weight, bias 초기화
        # 순전파 계산
        output = model(train_x)
        # 오차계산
        loss = criterion(output, train_y)
        # 역전파 계산
        loss.backward()
        # 가중치 업데이트
        optimizer.step()
        # 누적 오차 계산
        total_loss += loss.data
    # 50회 반복마다 누적오차 출력
    if (epoch+1) % 50 == 0:
        print(epoch+1, total_loss)



# 계산 그래프 구성
X_test, y_test = Variable(X_test), Variable(y_test)
# 출력값 계산
result = torch.max(model(X_test).data, 1)[1]
			확률 최대값 


	0	1	2
	.22	.11	.66

# 모형의 정확도 측정
# gpu에 저장된 텐서를 cpu로 이동시킴
y_test=y_test.cpu()
result=result.cpu()
accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())
# 모형의 정확도 출력
accuracy



	학습모드	- 가중치 업데이트
	그래프모드

	추론모드


(60000, 28, 28)
샘플수   가로 세로


	0~255		=> 0.0 ~ 1.0
	black ~ white

	0~255/255.0


	(60000, 28, 28) 3차원 => (60000, 784) 2차원

X_train= X_train.reshape(-1,784) # 2차원
                        행, 열
			-1 
		
X_test= X_test.reshape(-1,784)
X_train=X_train/255. # 0.0 ~ 1.0 
X_test=X_test/255.




import torch
# 학습용 데이터 텐서 변환
# from_numpy() 넘파이배열을 텐서로 변환

	memory=>gpu

X_train = torch.from_numpy(X_train).float()
y_train = torch.from_numpy(y_train.astype('int32')).long()
# 검증용 데이터 텐서 변환
X_test = torch.from_numpy(X_test).float()
y_test = torch.from_numpy(y_test.astype('int32')).long()
# 변환된 텐서의 샘플수 확인
print(X_train.shape)
print(y_train.shape)




import torch.nn as nn
import torch.nn.functional as F
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 256)
                             in   out
        self.fc2 = nn.Linear(256, 256)
        self.fc3 = nn.Linear(256, 256)
        self.fc4 = nn.Linear(256, 128)
        self.fc5 = nn.Linear(128, 128)
        self.fc6 = nn.Linear(128, 10)
    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = F.relu(self.fc4(x))
        x = F.relu(self.fc5(x))
        x = self.fc6(x)
        return F.log_softmax(x,dim=0)
    
model = Net().cuda()



result = torch.max(model(X_test).data, 1)[1]
		확률이 가장 높은 값

y_test=y_test.cpu()
result=result.cpu()

	gpu=>cpu

print(result[:5]) # 출력값
print(y_test.data.numpy()[:5]) #실제값
		numpy() memory로 이동

# 모형의 정확도 측정
accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())
# 모형의 정확도 출력
accuracy




pip uninstall torch
pip uninstall torchvision 
pip uninstall torchaudio 



pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118





# 샘플수, 채널(흑백1/컬러3), 가로, 세로
X_train= X_train.reshape(-1,1,28,28)
                        
X_test= X_test.reshape(-1,1,28,28)
X_train=X_train/255.
X_test=X_test/255.



import torch.nn as nn
import torch.nn.functional as F
# 신경망 구성
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5 ) # 입력 채널 수(흑백1,컬러3), 출력 채널 수, 필터 크기
                               in out 5x5

		=> relu
		=> maxpooling

        self.conv2 = nn.Conv2d(6, 16, 5)
        # Fully Connected Layer
        self.fc1 = nn.Linear(256, 64)
        self.fc2 = nn.Linear(64, 10)
    
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2) # 풀링 영역 크기 2x2
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, 256)
		1차원으로 변환

        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x,dim=0)
    
# 인스턴스 생성
model = Net().cuda()



X_test, y_test = Variable(X_test), Variable(y_test)
# [0] values, [1] indices
# 모형이 분류한 값들(10개) 중 가장 큰 값과 인덱스
# 출력이 0 또는 1이 되게 함
result = torch.max(model(X_test).data, 1)[1]
#print(result)
# 모형의 정확도 측정
# gpu에 저장된 텐서를 cpu로 이동시킴
y_test=y_test.cpu()
result=result.cpu()
accuracy = sum(y_test.data.numpy() == result.numpy()) / len(y_test.data.numpy())
accuracy


TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.





# batch_size, channels, height, width
summary(model, input_size=(batch_size, 1, 28, 28))



import gzip
import numpy as np
#이미지 압축파일을 오픈
with gzip.open('d:/data/fashion-mnist/train-images-idx3-ubyte.gz', 'rb') as f:
	압축파일							read binary
    # frombuffer(바이트배열, 자료형, 시작점)
    mnist_data=np.frombuffer(f.read(), np.uint8, offset=16)
    # 차원 변경
    mnist_data = mnist_data.reshape(-1, 784)









