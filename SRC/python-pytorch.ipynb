{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch ( facebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Tensor\n",
    "* 다차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 학습시킬때는 tensor로 사용 ( cpu, gpu 사용 )\n",
    "# predict할때는 다시 numpy \n",
    "\n",
    "li = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "#넘파이배열을 텐서로 변환\n",
    "\n",
    "tensor1 = torch.tensor(li)\n",
    "\n",
    "tensor2 = torch.as_tensor(li)\n",
    "\n",
    "tensor3 = torch.from_numpy(li)\n",
    "\n",
    "print(tensor1)\n",
    "\n",
    "print(tensor2)\n",
    "\n",
    "print(tensor3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "#텐서를 넘파이배열로 변환\n",
    "\n",
    "print(tensor1.numpy())\n",
    "\n",
    "print(tensor2.numpy())\n",
    "\n",
    "print(tensor3.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074])\n",
      "tensor([ 0.5507,  0.2704,  0.6472,  0.2490, -0.3354])\n",
      "tensor([8, 4, 3, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# torch 난수 생성\n",
    "\n",
    "torch.manual_seed(0) #랜덤시드 고정\n",
    "\n",
    "a = torch.rand(5) # 0 ~ 1 사이의 5개의 난수\n",
    "\n",
    "b = torch.randn(5) # 평균 0, 표준편차 1인 5개의 난수\n",
    "\n",
    "c = torch.randint(10, size=(5,)) # 0~9 사이의 5개의 난수\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(b)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "print(torch.arange(1, 10)) # 1~9\n",
    "\n",
    "print(torch.ones((2, 5))) # 2행 5열, 1로 채움\n",
    "\n",
    "print(torch.zeros((3, 5))) #3행 5열, 0으로 채움\n",
    "\n",
    "print(torch.linspace(0, 10, 5)) # 0~10, 5등분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "#텐서의 형상 변환(reshape)\n",
    "\n",
    "t1 = torch.ones(4, 3)\n",
    "\n",
    "t2 = t1.view(3, 4) #3행 4열로 변환\n",
    "\n",
    "t3 = t1.view(12) #1차원 배열로 변환\n",
    "\n",
    "print(t1)\n",
    "\n",
    "print(t2)\n",
    "\n",
    "print(t3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "t1.view(1, 3, 4) #3차원으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) iris 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# iris 데이터셋 로딩\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "print(X[:5])\n",
    "\n",
    "print(y[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "<class 'numpy.ndarray'>\n",
      "(120, 4)\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split( X, y, random_state=10, test_size=0.2, stratify=y, shuffle=True )\n",
    "\n",
    "print(len(X_train))    \n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#신경망 모형\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        #input layer, Linear 선형함수(1차함수)\n",
    "\n",
    "        #input nodes, output nodes 50\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim,50) \n",
    "\n",
    "        self.layer2 = nn.Linear(50, 20)\n",
    "\n",
    "        self.layer3 = nn.Linear(20, 3)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.layer1(x))\n",
    "\n",
    "        x = F.relu(self.layer2(x))\n",
    "\n",
    "        # 출력층의 활성화함수 - 소프트맥스\n",
    "\n",
    "        x = F.softmax(self.layer3(x), dim=0)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "import torch\n",
    "\n",
    "model = Model(X_train.shape[1]) # 초기화함수의 input_dim으로 변수개수가 전달됨\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 최적화함수 정의\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() #손실함수 정의\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 1.098368763923645\n",
      "Epoch 2\n",
      "loss: 1.09757661819458\n",
      "Epoch 3\n",
      "loss: 1.0969760417938232\n",
      "Epoch 4\n",
      "loss: 1.0962201356887817\n",
      "Epoch 5\n",
      "loss: 1.0953227281570435\n",
      "Epoch 6\n",
      "loss: 1.0942963361740112\n",
      "Epoch 7\n",
      "loss: 1.093174695968628\n",
      "Epoch 8\n",
      "loss: 1.0920960903167725\n",
      "Epoch 9\n",
      "loss: 1.0910488367080688\n",
      "Epoch 10\n",
      "loss: 1.0901483297348022\n",
      "Epoch 11\n",
      "loss: 1.0894235372543335\n",
      "Epoch 12\n",
      "loss: 1.088867425918579\n",
      "Epoch 13\n",
      "loss: 1.0883787870407104\n",
      "Epoch 14\n",
      "loss: 1.087942123413086\n",
      "Epoch 15\n",
      "loss: 1.0875487327575684\n",
      "Epoch 16\n",
      "loss: 1.0872578620910645\n",
      "Epoch 17\n",
      "loss: 1.0870704650878906\n",
      "Epoch 18\n",
      "loss: 1.0868990421295166\n",
      "Epoch 19\n",
      "loss: 1.0867153406143188\n",
      "Epoch 20\n",
      "loss: 1.0865654945373535\n",
      "Epoch 21\n",
      "loss: 1.086439847946167\n",
      "Epoch 22\n",
      "loss: 1.0863085985183716\n",
      "Epoch 23\n",
      "loss: 1.086158275604248\n",
      "Epoch 24\n",
      "loss: 1.0859640836715698\n",
      "Epoch 25\n",
      "loss: 1.0857325792312622\n",
      "Epoch 26\n",
      "loss: 1.0855315923690796\n",
      "Epoch 27\n",
      "loss: 1.085354208946228\n",
      "Epoch 28\n",
      "loss: 1.0851529836654663\n",
      "Epoch 29\n",
      "loss: 1.084934115409851\n",
      "Epoch 30\n",
      "loss: 1.0846964120864868\n",
      "Epoch 31\n",
      "loss: 1.0844676494598389\n",
      "Epoch 32\n",
      "loss: 1.0842632055282593\n",
      "Epoch 33\n",
      "loss: 1.0840269327163696\n",
      "Epoch 34\n",
      "loss: 1.0838048458099365\n",
      "Epoch 35\n",
      "loss: 1.0836102962493896\n",
      "Epoch 36\n",
      "loss: 1.083433985710144\n",
      "Epoch 37\n",
      "loss: 1.0832743644714355\n",
      "Epoch 38\n",
      "loss: 1.0831400156021118\n",
      "Epoch 39\n",
      "loss: 1.0830436944961548\n",
      "Epoch 40\n",
      "loss: 1.0829625129699707\n",
      "Epoch 41\n",
      "loss: 1.082894206047058\n",
      "Epoch 42\n",
      "loss: 1.0828334093093872\n",
      "Epoch 43\n",
      "loss: 1.0827800035476685\n",
      "Epoch 44\n",
      "loss: 1.082739233970642\n",
      "Epoch 45\n",
      "loss: 1.082710862159729\n",
      "Epoch 46\n",
      "loss: 1.0826863050460815\n",
      "Epoch 47\n",
      "loss: 1.0826643705368042\n",
      "Epoch 48\n",
      "loss: 1.0826467275619507\n",
      "Epoch 49\n",
      "loss: 1.0826315879821777\n",
      "Epoch 50\n",
      "loss: 1.0826176404953003\n",
      "Epoch 51\n",
      "loss: 1.0826042890548706\n",
      "Epoch 52\n",
      "loss: 1.0825917720794678\n",
      "Epoch 53\n",
      "loss: 1.0825788974761963\n",
      "Epoch 54\n",
      "loss: 1.0825666189193726\n",
      "Epoch 55\n",
      "loss: 1.0825542211532593\n",
      "Epoch 56\n",
      "loss: 1.0825413465499878\n",
      "Epoch 57\n",
      "loss: 1.0825282335281372\n",
      "Epoch 58\n",
      "loss: 1.0825145244598389\n",
      "Epoch 59\n",
      "loss: 1.0825005769729614\n",
      "Epoch 60\n",
      "loss: 1.0824878215789795\n",
      "Epoch 61\n",
      "loss: 1.082477331161499\n",
      "Epoch 62\n",
      "loss: 1.0824673175811768\n",
      "Epoch 63\n",
      "loss: 1.0824579000473022\n",
      "Epoch 64\n",
      "loss: 1.0824490785598755\n",
      "Epoch 65\n",
      "loss: 1.082440733909607\n",
      "Epoch 66\n",
      "loss: 1.0824328660964966\n",
      "Epoch 67\n",
      "loss: 1.0824252367019653\n",
      "Epoch 68\n",
      "loss: 1.0824179649353027\n",
      "Epoch 69\n",
      "loss: 1.0824108123779297\n",
      "Epoch 70\n",
      "loss: 1.0824042558670044\n",
      "Epoch 71\n",
      "loss: 1.0823975801467896\n",
      "Epoch 72\n",
      "loss: 1.0823910236358643\n",
      "Epoch 73\n",
      "loss: 1.082384467124939\n",
      "Epoch 74\n",
      "loss: 1.0823780298233032\n",
      "Epoch 75\n",
      "loss: 1.0823715925216675\n",
      "Epoch 76\n",
      "loss: 1.0823653936386108\n",
      "Epoch 77\n",
      "loss: 1.0823590755462646\n",
      "Epoch 78\n",
      "loss: 1.0823529958724976\n",
      "Epoch 79\n",
      "loss: 1.0823471546173096\n",
      "Epoch 80\n",
      "loss: 1.0823410749435425\n",
      "Epoch 81\n",
      "loss: 1.0823355913162231\n",
      "Epoch 82\n",
      "loss: 1.082330346107483\n",
      "Epoch 83\n",
      "loss: 1.0823253393173218\n",
      "Epoch 84\n",
      "loss: 1.0823209285736084\n",
      "Epoch 85\n",
      "loss: 1.0823167562484741\n",
      "Epoch 86\n",
      "loss: 1.0823124647140503\n",
      "Epoch 87\n",
      "loss: 1.0823084115982056\n",
      "Epoch 88\n",
      "loss: 1.0823043584823608\n",
      "Epoch 89\n",
      "loss: 1.0823006629943848\n",
      "Epoch 90\n",
      "loss: 1.0822968482971191\n",
      "Epoch 91\n",
      "loss: 1.0822936296463013\n",
      "Epoch 92\n",
      "loss: 1.0822904109954834\n",
      "Epoch 93\n",
      "loss: 1.082287311553955\n",
      "Epoch 94\n",
      "loss: 1.0822843313217163\n",
      "Epoch 95\n",
      "loss: 1.0822813510894775\n",
      "Epoch 96\n",
      "loss: 1.0822786092758179\n",
      "Epoch 97\n",
      "loss: 1.0822759866714478\n",
      "Epoch 98\n",
      "loss: 1.0822734832763672\n",
      "Epoch 99\n",
      "loss: 1.0822712182998657\n",
      "Epoch 100\n",
      "loss: 1.0822688341140747\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#넘파이배열로부터 텐서를 만들고\n",
    "X_train = Variable(torch.from_numpy(np.array(X_train))).float()  # 메모리 => cpu,gpu\n",
    "y_train = Variable(torch.from_numpy(np.array(y_train))).long()\n",
    "#label = Variable(torch.from_numpy(np.array(label)).float()).to(device)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    print(\"Epoch\",epoch)\n",
    "\n",
    "    #예측값\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    #손실함수에 예측값과 실제값을 입력\n",
    "\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    print('loss:',loss.item())\n",
    "\n",
    "    \n",
    "\n",
    "    # 경사 초기화\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward() # 역전파\n",
    "\n",
    "    optimizer.step() # 가중치 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4967e-07, 4.3045e-03, 8.2617e-05],\n",
       "        [3.3400e-02, 2.4500e-07, 6.6396e-12],\n",
       "        [7.2018e-08, 1.2540e-03, 2.1329e-04],\n",
       "        [2.8003e-08, 7.0835e-04, 6.0539e-04],\n",
       "        [6.8303e-06, 3.0979e-01, 9.3650e-07]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "# Prediction\n",
    "\n",
    "X_test = Variable(torch.from_numpy(X_test)).float()\n",
    "\n",
    "pred = model(X_test)\n",
    "\n",
    "pred[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 2, 0, 2, 2, 0, 0, 1, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2,\n",
       "       2, 0, 0, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.argmax(pred.data.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "\n",
    "accuracy_score(y_test, np.argmax(pred.data.numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "\n",
    "torch.save(model, \"../MODL/iris-torch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "model2 = torch.load(\"../MODL/iris-torch.h5\")\n",
    "\n",
    "\n",
    "#np.argmax(model2(X_test[0]).data.numpy())\n",
    "\n",
    "#X_test = Variable(torch.from_numpy(X_test)).float()\n",
    "np.argmax(model2(Variable(torch.from_numpy(X_test[0])).float()).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Model                                    [32, 3]                   --\n",
       "├─Linear: 1-1                            [32, 50]                  250\n",
       "├─Linear: 1-2                            [32, 20]                  1,020\n",
       "├─Linear: 1-3                            [32, 3]                   63\n",
       "==========================================================================================\n",
       "Total params: 1,333\n",
       "Trainable params: 1,333\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.02\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "\n",
    "#pip install torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model)\n",
    "\n",
    "# input_size=(batch size, input nodes)\n",
    "\n",
    "summary(model, input_size=(32, 4)) # 미니배치"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
